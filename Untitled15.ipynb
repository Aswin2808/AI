{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgDISLKrE1eAFQvviIKMGZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aswin2808/AI/blob/main/Untitled15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-cPQOmpIT-w",
        "outputId": "13c83fcc-e010-43dc-bee9-1bbe85127a3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Enter an English word/sentence to translate (or 'exit' to quit): hiii\n",
            "hiii -> hiii\n",
            "Enter an English word/sentence to translate (or 'exit' to quit): helloo\n",
            "helloo -> Hola.\n",
            "Enter an English word/sentence to translate (or 'exit' to quit): oneee\n",
            "oneee -> oneee\n",
            "Enter an English word/sentence to translate (or 'exit' to quit): one\n",
            "one -> uno\n",
            "Enter an English word/sentence to translate (or 'exit' to quit): lion\n",
            "lion -> león\n",
            "Enter an English word/sentence to translate (or 'exit' to quit): go madrid\n",
            "go madrid -> ir madrid\n",
            "Enter an English word/sentence to translate (or 'exit' to quit): go\n",
            "go -> ¡Vamos!\n",
            "Enter an English word/sentence to translate (or 'exit' to quit): exit\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "import spacy\n",
        "import nltk\n",
        "\n",
        "# Ensure that you have the necessary models and corpora downloaded\n",
        "nltk.download('punkt')  # Tokenizers\n",
        "\n",
        "# Download spaCy models\n",
        "spacy.cli.download(\"en_core_web_sm\")\n",
        "spacy.cli.download(\"es_core_news_sm\")\n",
        "\n",
        "# Load spaCy models\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "nlp_es = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "# Load the pre-trained translation model and tokenizer\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-es\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "# Define a translation function using the pre-trained model\n",
        "def translate_sentence(sentence):\n",
        "    # Tokenize and prepare the input\n",
        "    translated = tokenizer.prepare_seq2seq_batch(src_texts=[sentence], return_tensors=\"pt\")\n",
        "    # Generate translation\n",
        "    translated_ids = model.generate(**translated)\n",
        "    # Decode the translated text\n",
        "    translated_text = tokenizer.batch_decode(translated_ids, skip_special_tokens=True)\n",
        "    return translated_text[0]\n",
        "\n",
        "# Interactive input loop for testing\n",
        "while True:\n",
        "    test_sentence = input(\"Enter an English word/sentence to translate (or 'exit' to quit): \").strip()\n",
        "    if test_sentence.lower() == \"exit\":\n",
        "        break\n",
        "\n",
        "    # Tokenize the input sentence using spaCy\n",
        "    tokens = [token.text for token in nlp_en(test_sentence)]\n",
        "\n",
        "    # Translate the sentence using the pre-trained model\n",
        "    translated_sentence = translate_sentence(test_sentence)\n",
        "    print(f\"{test_sentence} -> {translated_sentence}\")\n"
      ]
    }
  ]
}