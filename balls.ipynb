{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1hyGzE2Rcxk2TYWa-gLsYc2hx4qzOQF8R",
      "authorship_tag": "ABX9TyNv0Y7Enek1Lxvt89sCHSF/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aswin2808/AI/blob/main/balls.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qvNXGtrpDupD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/drive/MyDrive/balls/train'\n",
        "test_dir = '/content/drive/MyDrive/balls/test'\n",
        "img_path ='/content/drive/MyDrive/cktball.jpg'"
      ],
      "metadata": {
        "id": "6M_vgV7HECI-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "IMG_HEIGHT = 128\n",
        "IMG_WIDTH = 128\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20"
      ],
      "metadata": {
        "id": "Cc-9GirNErEa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation for training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n"
      ],
      "metadata": {
        "id": "Lwie_Z-wEu3I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only rescale for testing data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n"
      ],
      "metadata": {
        "id": "fenKruOdE9AZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jirsHeuhE_dP",
        "outputId": "3847273f-ef70-4d87-ee9b-10dbde0b91d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1617 images belonging to 3 classes.\n",
            "Found 406 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # 3 classes: volleyball, football, cricket ball\n",
        "])"
      ],
      "metadata": {
        "id": "7eH2dEgOFL7v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "u3Y_JR8gGK8d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2lPoPG2GS59",
        "outputId": "5e1c7dc9-0a12-497e-b35c-227bdc9a222c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.5042 - accuracy: 0.7950\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.4917 - accuracy: 0.8088\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.4990 - accuracy: 0.7987\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 76s 2s/step - loss: 0.4789 - accuracy: 0.8013\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.4642 - accuracy: 0.8208\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.4542 - accuracy: 0.8259\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 76s 2s/step - loss: 0.4652 - accuracy: 0.8252\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.4681 - accuracy: 0.8177\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.4587 - accuracy: 0.8170\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 76s 1s/step - loss: 0.4526 - accuracy: 0.8215\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.4313 - accuracy: 0.8215\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.4265 - accuracy: 0.8372\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.4153 - accuracy: 0.8297\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.4135 - accuracy: 0.8315\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.4428 - accuracy: 0.8158\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 76s 1s/step - loss: 0.4093 - accuracy: 0.8372\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.3872 - accuracy: 0.8517\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.3956 - accuracy: 0.8580\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.3720 - accuracy: 0.8574\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.4027 - accuracy: 0.8309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model\n",
        "model.save('ball_classification_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkUjIBkwGanh",
        "outputId": "1ade778b-8d19-446e-f510-7e4420795901"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // BATCH_SIZE)\n",
        "print(f'Test Accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVibxb_BZWTT",
        "outputId": "1e94de42-81dd-4a3c-ed2d-a42571622c77"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 95s 9s/step - loss: 0.4284 - accuracy: 0.8438\n",
            "Test Accuracy: 0.84375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction function\n",
        "def predict_image(image_path):\n",
        "    if not os.path.exists(image_path):\n",
        "        return \"File not found\"\n",
        "\n",
        "    img = load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Normalize the image\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = np.argmax(predictions)\n",
        "    class_labels = ['volleyball', 'football', 'cricket ball']\n",
        "    return class_labels[predicted_class] if predicted_class in range(len(class_labels)) else \"Not found\"\n",
        "\n",
        "# Make a Prediction"
      ],
      "metadata": {
        "id": "62-6Uh2gZXJR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predicted_class = predict_image(img_path)\n",
        "print(f'Predicted Class: {predicted_class}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRk4kW98a74g",
        "outputId": "edd807b0-1b0b-492e-8835-653fcd6f1553"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 51ms/step\n",
            "Predicted Class: volleyball\n"
          ]
        }
      ]
    }
  ]
}